{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QEwyHcnBWOc1"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x5cTHIkoWe6X"
   },
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(root = \".\", train = True, download = True, transform = transforms.ToTensor())\n",
    "test_set = torchvision.datasets.FashionMNIST(root = \".\", train = False, download = True, transform = transforms.ToTensor())\n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(train_set, batch_size = 32, shuffle = True) \n",
    "testing_loader = torch.utils.data.DataLoader(test_set, batch_size = 32, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aBl9A6gIPocU"
   },
   "outputs": [],
   "source": [
    "def showImage(img):\n",
    "  npimg = img.numpy()\n",
    "  plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j7bywdtAP4N-"
   },
   "outputs": [],
   "source": [
    "images, label = next(iter(training_loader))\n",
    "showImage(torchvision.utils.make_grid(images))\n",
    "print((label))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KUYgDWxvWqGU"
   },
   "outputs": [],
   "source": [
    "class IdentifyCloth(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(IdentifyCloth, self).__init__()\n",
    "    # network with cnn and ReLU as activation function \n",
    "    self.cnn_model = nn.Sequential(nn.Conv2d(1,32, kernel_size = 5),nn.ReLU(),nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "                                   nn.Conv2d(32,64,kernel_size = 5),nn.ReLU(),nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "    self.fully_connected =  nn.Sequential(nn.Linear(64*4*4, 1024), nn.ReLU(), nn.Linear(1024,256), nn.ReLU(), nn.Linear(256, 10))\n",
    "    \n",
    "    # network with cnn and Tanh as activation function \n",
    "    # self.cnn_model = nn.Sequential(nn.Conv2d(1,32, kernel_size = 5),nn.Tanh(),nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "    #                                nn.Conv2d(32,64,kernel_size = 5),nn.Tanh(),nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "    # self.fully_connected =  nn.Sequential(nn.Linear(64*4*4, 1024), nn.Tanh(), nn.Linear(1024,256), nn.Tanh(), nn.Linear(256, 10))\n",
    "    \n",
    "    # network with cnn and Sigmod as activation function \n",
    "    # self.cnn_model = nn.Sequential(nn.Conv2d(1,32, kernel_size = 5),nn.Sigmoid(),nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "    #                                nn.Conv2d(32,64,kernel_size = 5),nn.Sigmoid(),nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "    # self.fully_connected =  nn.Sequential(nn.Linear(64*4*4, 1024), nn.Sigmoid(), nn.Linear(1024,256), nn.Sigmoid(), nn.Linear(256, 10))\n",
    "\n",
    "    # network with cnn and ELU as activation function \n",
    "    # self.cnn_model = nn.Sequential(nn.Conv2d(1,32, kernel_size = 5),nn.ELU(),nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "    #                                nn.Conv2d(32,64,kernel_size = 5),nn.ELU(),nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "    # self.fully_connected =  nn.Sequential(nn.Linear(64*4*4, 1024), nn.ELU(), nn.Linear(1024,256), nn.ELU(), nn.Linear(256, 10))\n",
    "\n",
    "    # network with cnn and ReLU as activation function with a drop in second fully connected layer.\n",
    "    # self.cnn_model = nn.Sequential(nn.Conv2d(1,32, kernel_size = 5),nn.ReLU(),nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "    #                                nn.Conv2d(32,64,kernel_size = 5),nn.ReLU(),nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "    # self.fully_connected =  nn.Sequential(nn.Linear(64*4*4, 1024), nn.ReLU(), nn.Linear(1024,256),nn.Dropout(p=0.2), nn.ReLU(), nn.Linear(256, 10))\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.cnn_model(x)\n",
    "    x = x.reshape(-1, 64*4*4)\n",
    "    x = self.fully_connected(x)\n",
    "    return x\n",
    "def initWeight(layer):\n",
    "  if isinstance(layer, nn.Linear):\n",
    "    nn.init.xavier_uniform_(layer.weight, gain=1.0)\n",
    "    # nn.init.normal_(layer.weight, 0.5, 2)\n",
    "\n",
    "\n",
    "def evaluation(dataloader):\n",
    "  total, correct = 0,0\n",
    "  model.eval()\n",
    "  for data in dataloader:\n",
    "    inputs, labels = data\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    outputs = model(inputs)\n",
    "    _, pred = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (pred == labels).sum().item()\n",
    "  return 100 * correct / total\n",
    "\n",
    "model = IdentifyCloth().to(device)\n",
    "calculate_loss = nn.CrossEntropyLoss()\n",
    "model.apply(initWeight)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "max_epoch = 50\n",
    "loss_epoch_array = []\n",
    "loss_epoch = 0\n",
    "train_accuracy = []\n",
    "valid_accuracy = []\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "  loss_epoch = 0\n",
    "  for i, data in enumerate(training_loader, 0):\n",
    "    model.train()\n",
    "    input, label = data\n",
    "    input, label = input.to(device), label.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    output = model(input)\n",
    "    loss = calculate_loss(output, label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_epoch += loss.item()\n",
    "  loss_epoch_array.append(loss_epoch)\n",
    "  train_accuracy.append(evaluation(training_loader))\n",
    "  valid_accuracy.append(evaluation(testing_loader))\n",
    "  print(\"Epoch {}: loss: {}, train accuracy: {}, valid accuracy:{}\".format(epoch + 1, loss_epoch_array[-1], train_accuracy[-1], valid_accuracy[-1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kN6hFZtSQ-d1"
   },
   "outputs": [],
   "source": [
    "plt.plot(range(1,51), train_accuracy, 'r', label = 'Training Acc')\n",
    "plt.plot(range(1,51), valid_accuracy, 'b', label = 'Testing Acc')\n",
    "plt.title('Accuracy vs Epoch')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "phth7FPsLx77"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0y4n8AIXMODw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x52vCrjIN475"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Coursework-2-solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
